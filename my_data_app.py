import streamlit as st
import pandas as pd
import sqlite3
from requests import get
from bs4 import BeautifulSoup as bs
import time

# Configuration de la page
st.set_page_config(page_title="CoinAfrique Animal Scraper", layout="wide")

# Style personnalis√© avec le th√®me sombre
st.markdown("""
<style>
    /* Background principal */
    .stApp {
        background: linear-gradient(135deg, #1a1d29 0%, #2d3748 100%);
    }
    
    /* Sidebar */
    [data-testid=stSidebar] {
        background: linear-gradient(180deg, #1e2433 0%, #252d3d 100%);
        border-right: 1px solid rgba(255, 255, 255, 0.1);
    }
    
    /* Cartes et containers */
    .stMarkdown, .stDataFrame {
        background-color: rgba(255, 255, 255, 0.05);
        border-radius: 10px;
        padding: 10px;
    }
    
    /* Titres */
    h1, h2, h3 {
        color: #ffffff !important;
    }
    
    /* M√©triques */
    [data-testid="stMetricValue"] {
        color: #4FD1C5 !important;
        font-weight: bold;
    }
    
    /* Boutons */
    .stButton>button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.5rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
    }
    
    /* Radio buttons dans la sidebar */
    .stRadio > label {
        background-color: rgba(255, 255, 255, 0.05);
        padding: 10px;
        border-radius: 8px;
        margin: 5px 0;
        transition: all 0.3s ease;
    }
    
    .stRadio > label:hover {
        background-color: rgba(255, 255, 255, 0.1);
        transform: translateX(5px);
    }
    
    /* Texte */
    p, span, label {
        color: #e2e8f0 !important;
    }
    
    /* Inputs */
    .stTextInput>div>div>input, .stSelectbox>div>div>select {
        background-color: rgba(255, 255, 255, 0.1);
        color: white;
        border: 1px solid rgba(255, 255, 255, 0.2);
        border-radius: 8px;
    }
    
    /* Tableaux */
    .dataframe {
        background-color: rgba(255, 255, 255, 0.05) !important;
        color: #e2e8f0 !important;
    }
    
    /* Success/Info/Warning boxes */
    .stSuccess, .stInfo, .stWarning {
        background-color: rgba(255, 255, 255, 0.1);
        border-radius: 10px;
    }
</style>
""", unsafe_allow_html=True)

st.markdown("<h1 style='text-align: center; color: #4FD1C5; text-shadow: 0 0 20px rgba(79, 209, 197, 0.5);'>üêæ COINAFRIQUE ANIMAL DATA APP</h1>", unsafe_allow_html=True)

st.markdown("""
<div style='background: rgba(255, 255, 255, 0.05); padding: 20px; border-radius: 10px; border-left: 4px solid #4FD1C5;'>
Cette application vous permet de t√©l√©charger des donn√©es scrap√©es sur les animaux de CoinAfrique S√©n√©gal
<ul style='margin-top: 10px;'>
    <li><b>Librairies Python:</b> pandas, streamlit, sqlite3, beautifulsoup4, requests</li>
    <li><b>Source de donn√©es:</b> <a href='https://sn.coinafrique.com/' target='_blank' style='color: #4FD1C5;'>CoinAfrique S√©n√©gal</a></li>
</ul>
</div>
""", unsafe_allow_html=True)

# Fonction pour cr√©er la base de donn√©es SQLite
def init_database():
    conn = sqlite3.connect('data/coinafrique_animals.db')
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS animals
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  category TEXT,
                  name TEXT,
                  price TEXT,
                  address TEXT,
                  image_url TEXT,
                  scrape_date TEXT)''')
    conn.commit()
    conn.close()

# Fonction de scraping am√©lior√©e avec gestion des valeurs manquantes
def scrape_all_pages(base_url, category_name, max_pages=10):
    df = pd.DataFrame()

    for page in range(1, max_pages + 1):
        try:
            print(f"Scraping page {page}...")
            
            url = f"{base_url}?page={page}"
            res = get(url, timeout=10)
            soup = bs(res.content, 'html.parser')
            containers = soup.find_all('div', class_='col s6 m4 l3')

            if not containers:
                print("Plus d'annonces trouv√©es. Fin du scraping.")
                break

            data = []
            for container in containers:
                # Extraire le nom (si absent, mettre "Non sp√©cifi√©")
                try:
                    name = container.find('p', 'ad__card-description').text.strip()
                except:
                    name = "Non sp√©cifi√©"
                
                # Extraire le prix (si absent, mettre "0")
                try:
                    price = container.find('p', 'ad__card-price').text.replace('CFA', '').replace(' ', '').strip()
                    if not price:
                        price = "0"
                except:
                    price = "0"
                
                # Extraire l'adresse (si absente, mettre "Non sp√©cifi√©e")
                try:
                    adresse = container.find('p', 'ad__card-location').span.text.strip()
                except:
                    adresse = "Non sp√©cifi√©e"
                
                # Extraire l'URL de l'image (si absente, mettre "Non disponible")
                try:
                    image_url = container.find('img', class_='ad__card-img')['src']
                except:
                    image_url = "Non disponible"

                dic = {
                    'category': category_name,
                    'name': name,
                    'price': price,
                    'address': adresse,
                    'image_url': image_url,
                    'scrape_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                data.append(dic)

            DF = pd.DataFrame(data)
            df = pd.concat([df, DF], axis=0).reset_index(drop=True)
            time.sleep(1)
            
        except Exception as e:
            print(f"Erreur page {page}: {str(e)}")
            break

    return df

# Fonction pour nettoyer les donn√©es
def clean_data(df):
    df_clean = df.copy()
    
    # Nettoyer les prix (enlever les caract√®res non num√©riques)
    df_clean['price_clean'] = df_clean['price'].str.replace(r'\D', '', regex=True)
    df_clean['price_clean'] = pd.to_numeric(df_clean['price_clean'], errors='coerce')
    
    # Supprimer les doublons
    df_clean = df_clean.drop_duplicates(subset=['name', 'address'])
    
    # Supprimer les lignes avec des prix manquants
    df_clean = df_clean.dropna(subset=['price_clean'])
    
    return df_clean

# Fonction pour sauvegarder dans SQLite
def save_to_database(df):
    conn = sqlite3.connect('data/coinafrique_animals.db')
    df.to_sql('animals', conn, if_exists='append', index=False)
    conn.close()

# Fonction pour charger depuis SQLite
def load_from_database():
    try:
        conn = sqlite3.connect('data/coinafrique_animals.db')
        df = pd.read_sql_query("SELECT * FROM animals", conn)
        conn.close()
        return df
    except:
        return pd.DataFrame()

# Fonction pour afficher les donn√©es (adapt√©e de votre code)
def load_data(dataframe, title, key):
    st.markdown("""
    <style>
    div.stButton {text-align:center}
    </style>""", unsafe_allow_html=True)
    
    if st.button(title, key=key):
        st.subheader('Dimension des donn√©es')
        st.write('Dimension: ' + str(dataframe.shape[0]) + ' lignes et ' + str(dataframe.shape[1]) + ' colonnes.')
        st.dataframe(dataframe)

# Styles pour les boutons (adapt√© de votre code)
st.markdown('''<style> .stButton>button {
    font-size: 12px;
    height: 3em;
    width: 25em;
}</style>''', unsafe_allow_html=True)

# Initialiser la base de donn√©es
init_database()

# ==================== SIDEBAR ====================
st.sidebar.markdown("""
<div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 20px;'>
    <h2 style='color: white; margin: 0; font-size: 24px;'>üêæ Animal Data</h2>
    <p style='color: rgba(255,255,255,0.9); font-size: 14px; margin: 5px 0 0 0;'>Application de scraping</p>
</div>
""", unsafe_allow_html=True)

st.sidebar.markdown("---")

# Navigation avec style
st.sidebar.markdown("""
<style>
    [data-testid=stSidebar] {
        background: linear-gradient(180deg, #1e2433 0%, #252d3d 100%);
    }
    
    /* Style pour le selectbox dropdown */
    .stSelectbox > div > div {
        background-color: rgba(255, 255, 255, 0.05);
        border: 1px solid rgba(79, 209, 197, 0.3);
        border-radius: 10px;
        transition: all 0.3s ease;
    }
    
    .stSelectbox > div > div:hover {
        border-color: #4FD1C5;
        box-shadow: 0 0 10px rgba(79, 209, 197, 0.3);
    }
    
    /* Style pour les options du dropdown */
    .stSelectbox [data-baseweb="select"] {
        background-color: rgba(255, 255, 255, 0.05);
    }
    
    .stSelectbox option {
        background-color: #252d3d;
        color: #e2e8f0;
        padding: 10px;
    }
    
    .stSelectbox option:hover {
        background-color: rgba(102, 126, 234, 0.3);
    }
</style>
""", unsafe_allow_html=True)

st.sidebar.markdown("<h3 style='color: #4FD1C5; margin-bottom: 15px;'>üìã Navigation</h3>", unsafe_allow_html=True)

menu = st.sidebar.selectbox(
    "Choisissez une section :",
    [
        "üîç Scraper des donn√©es", 
        "üì• T√©l√©charger donn√©es Web Scraper", 
        "üìä Dashboard (donn√©es nettoy√©es)", 
        "üìù Formulaires d'√©valuation"
    ],
    label_visibility="collapsed"
)

st.sidebar.markdown("---")

# Statistiques rapides dans la sidebar
st.sidebar.markdown("<h3 style='color: #4FD1C5; margin-bottom: 15px;'>üìä Statistiques rapides</h3>", unsafe_allow_html=True)
try:
    df_stats = load_from_database()
    if not df_stats.empty:
        col1, col2 = st.sidebar.columns(2)
        with col1:
            st.markdown(f"""
            <div style='background: rgba(79, 209, 197, 0.1); padding: 15px; border-radius: 10px; text-align: center;'>
                <p style='color: #4FD1C5; font-size: 24px; font-weight: bold; margin: 0;'>{len(df_stats)}</p>
                <p style='color: #e2e8f0; font-size: 12px; margin: 5px 0 0 0;'>Annonces</p>
            </div>
            """, unsafe_allow_html=True)
        with col2:
            st.markdown(f"""
            <div style='background: rgba(102, 126, 234, 0.1); padding: 15px; border-radius: 10px; text-align: center;'>
                <p style='color: #667eea; font-size: 24px; font-weight: bold; margin: 0;'>{df_stats['category'].nunique()}</p>
                <p style='color: #e2e8f0; font-size: 12px; margin: 5px 0 0 0;'>Cat√©gories</p>
            </div>
            """, unsafe_allow_html=True)
        
        df_clean_stats = clean_data(df_stats)
        if not df_clean_stats.empty and 'price_clean' in df_clean_stats.columns:
            avg_price = df_clean_stats['price_clean'].mean()
            st.markdown(f"""
            <div style='background: rgba(118, 75, 162, 0.1); padding: 15px; border-radius: 10px; text-align: center; margin-top: 10px;'>
                <p style='color: #764ba2; font-size: 20px; font-weight: bold; margin: 0;'>{avg_price:,.0f} CFA</p>
                <p style='color: #e2e8f0; font-size: 12px; margin: 5px 0 0 0;'>Prix moyen</p>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.sidebar.info("Aucune donn√©e disponible")
except:
    st.sidebar.info("Aucune donn√©e disponible")

st.sidebar.markdown("---")

# Informations suppl√©mentaires
st.sidebar.markdown("<h3 style='color: #4FD1C5; margin-bottom: 15px;'>‚ÑπÔ∏è √Ä propos</h3>", unsafe_allow_html=True)
st.sidebar.markdown("""
<div style='background: rgba(255, 255, 255, 0.05); padding: 15px; border-radius: 10px; font-size: 13px; color: #cbd5e0;'>
üì¶ <b style='color: #4FD1C5;'>Version:</b> 1.0.0<br>
üîß <b style='color: #4FD1C5;'>Tech:</b> Streamlit + BeautifulSoup<br>
üåê <b style='color: #4FD1C5;'>Source:</b> CoinAfrique SN<br>
</div>
""", unsafe_allow_html=True)

st.sidebar.markdown("---")

# Liens utiles
with st.sidebar.expander("üîó Liens utiles"):
    st.markdown("""
    <div style='font-size: 13px;'>
    ‚Ä¢ <a href='https://sn.coinafrique.com' target='_blank' style='color: #4FD1C5;'>CoinAfrique</a><br>
    ‚Ä¢ <a href='https://docs.streamlit.io' target='_blank' style='color: #4FD1C5;'>Documentation Streamlit</a><br>
    ‚Ä¢ <a href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/' target='_blank' style='color: #4FD1C5;'>BeautifulSoup Docs</a>
    </div>
    """, unsafe_allow_html=True)

# ==================== SECTION 1: SCRAPER ====================
if menu == "üîç Scraper des donn√©es":
    st.header("üîç Scraper des donn√©es sur plusieurs pages")
    
    st.info("‚ö†Ô∏è Le scraping peut prendre quelques minutes selon le nombre de pages.")
    
    categories = {
        "üêï Chiens": "https://sn.coinafrique.com/categorie/chiens",
        "üêë Moutons": "https://sn.coinafrique.com/categorie/moutons",
        "üêî Poules, lapins et pigeons": "https://sn.coinafrique.com/categorie/poules-lapins-et-pigeons",
        "ü¶é Autres animaux": "https://sn.coinafrique.com/categorie/autres-animaux"
    }
    
    col1, col2 = st.columns(2)
    
    with col1:
        selected_category = st.selectbox("Cat√©gorie √† scraper", list(categories.keys()))
    
    with col2:
        max_pages = st.slider("Nombre de pages", 1, 20, 5)
    
    if st.button("üöÄ Lancer le scraping", type="primary"):
        with st.spinner(f"Scraping en cours pour {selected_category}..."):
            category_name = selected_category.split(' ', 1)[1]  # Enlever l'emoji
            df_scraped = scrape_all_pages(categories[selected_category], category_name, max_pages)
            
            if not df_scraped.empty:
                st.success(f"‚úÖ {len(df_scraped)} annonces scrap√©es avec succ√®s !")
                
                # Sauvegarder dans la base de donn√©es
                save_to_database(df_scraped)
                st.info("üíæ Donn√©es sauvegard√©es dans la base de donn√©es SQLite")
                
                # Afficher un aper√ßu
                st.subheader("üìã Aper√ßu des donn√©es")
                st.dataframe(df_scraped.head(10))
                
                # T√©l√©charger imm√©diatement
                csv = df_scraped.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label=f"üì• T√©l√©charger {category_name} (CSV)",
                    data=csv,
                    file_name=f'{category_name.lower().replace(" ", "_")}.csv',
                    mime='text/csv',
                )
            else:
                st.warning("‚ö†Ô∏è Aucune donn√©e trouv√©e.")

# ==================== SECTION 2: T√âL√âCHARGER DONN√âES BRUTES ====================
elif menu == "üì• T√©l√©charger donn√©es Web Scraper":
    st.header("üì• T√©l√©charger les donn√©es brutes (non nettoy√©es)")
    
    st.markdown("""
    Cette section vous permet de t√©l√©charger les donn√©es scrap√©es avec Web Scraper (format brut, sans nettoyage).
    """)
    
    df_raw = load_from_database()
    
    if not df_raw.empty:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("üìä Total d'annonces", len(df_raw))
        with col2:
            st.metric("üìÇ Cat√©gories", df_raw['category'].nunique())
        with col3:
            st.metric("üìÖ Derni√®re mise √† jour", df_raw['scrape_date'].max()[:10] if 'scrape_date' in df_raw.columns else "N/A")
        
        # Grouper par cat√©gorie
        st.subheader("üìë R√©partition par cat√©gorie")
        category_counts = df_raw['category'].value_counts().reset_index()
        category_counts.columns = ['Cat√©gorie', 'Nombre d\'annonces']
        st.dataframe(category_counts, use_container_width=True)
        
        # Charger les donn√©es par cat√©gorie (comme votre code original)
        st.subheader("üìÅ Donn√©es par cat√©gorie")
        
        categories_list = df_raw['category'].unique()
        
        for idx, cat in enumerate(categories_list, 1):
            df_cat = df_raw[df_raw['category'] == cat]
            load_data(df_cat, f"Donn√©es {cat}", str(idx))
        
        # T√©l√©charger toutes les donn√©es
        st.subheader("üíæ T√©l√©charger toutes les donn√©es")
        csv_all = df_raw.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T√©l√©charger toutes les donn√©es (CSV)",
            data=csv_all,
            file_name='coinafrique_animals_all.csv',
            mime='text/csv',
        )
        
    else:
        st.info("‚ÑπÔ∏è Aucune donn√©e disponible. Veuillez d'abord scraper des donn√©es.")
        st.markdown("üëâ Allez dans **üîç Scraper des donn√©es** pour commencer.")

# ==================== SECTION 3: DASHBOARD ====================
elif menu == "üìä Dashboard (donn√©es nettoy√©es)":
    st.header("üìä Dashboard des donn√©es nettoy√©es")
    
    df_raw = load_from_database()
    
    if not df_raw.empty:
        df_clean = clean_data(df_raw)
        
        # M√©triques principales
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üìä Annonces totales", len(df_clean))
        with col2:
            st.metric("üí∞ Prix moyen", f"{df_clean['price_clean'].mean():,.0f} CFA")
        with col3:
            st.metric("üíµ Prix min", f"{df_clean['price_clean'].min():,.0f} CFA")
        with col4:
            st.metric("üí∏ Prix max", f"{df_clean['price_clean'].max():,.0f} CFA")
        
        # Statistiques par cat√©gorie
        st.subheader("üìà Statistiques par cat√©gorie")
        category_stats = df_clean.groupby('category').agg({
            'price_clean': ['count', 'mean', 'min', 'max']
        }).round(0)
        category_stats.columns = ['Nombre', 'Prix moyen (CFA)', 'Prix min (CFA)', 'Prix max (CFA)']
        st.dataframe(category_stats, use_container_width=True)
        
        # Graphiques
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üí∞ Prix moyen par cat√©gorie")
            avg_prices = df_clean.groupby('category')['price_clean'].mean().sort_values(ascending=False)
            st.bar_chart(avg_prices)
        
        with col2:
            st.subheader("üìä Nombre d'annonces par cat√©gorie")
            counts = df_clean['category'].value_counts()
            st.bar_chart(counts)
        
        # Top localisations
        st.subheader("üìç Top 10 des localisations")
        top_locations = df_clean['address'].value_counts().head(10)
        st.bar_chart(top_locations)
        
        # Explorer les donn√©es
        st.subheader("üîç Explorer les donn√©es nettoy√©es")
        
        # Filtre par cat√©gorie
        selected_cat = st.multiselect(
            "Filtrer par cat√©gorie",
            options=df_clean['category'].unique(),
            default=df_clean['category'].unique()
        )
        
        df_filtered = df_clean[df_clean['category'].isin(selected_cat)]
        
        st.write(f"**{len(df_filtered)}** annonces affich√©es")
        st.dataframe(df_filtered[['category', 'name', 'price', 'price_clean', 'address']], use_container_width=True)
        
        # T√©l√©charger les donn√©es nettoy√©es
        csv_clean = df_clean.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T√©l√©charger les donn√©es nettoy√©es (CSV)",
            data=csv_clean,
            file_name='coinafrique_animals_clean.csv',
            mime='text/csv',
        )
        
    else:
        st.info("‚ÑπÔ∏è Aucune donn√©e disponible. Veuillez d'abord scraper des donn√©es.")

# ==================== SECTION 4: FORMULAIRES D'√âVALUATION ====================
elif menu == "üìù Formulaires d'√©valuation":
    st.header("üìù Formulaires d'√©valuation de l'application")
    
    st.markdown("""
    Votre avis est important pour nous aider √† am√©liorer cette application. 
    Merci de prendre quelques instants pour r√©pondre √† l'un de ces questionnaires.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìã Formulaire KoboToolbox")
        st.markdown("""
        Remplissez le formulaire d'√©valuation sur **KoboToolbox** pour nous faire part de votre exp√©rience.
        
        Ce formulaire permet une collecte de donn√©es structur√©e et professionnelle.
        """)
        
        st.link_button(
            "üîó Ouvrir le formulaire KoboToolbox",
            "https://ee.kobotoolbox.org/x/JWIzi1ib",
            use_container_width=True
        )
        
        st.markdown("---")
        st.info("üí° **KoboToolbox** est une plateforme de collecte de donn√©es utilis√©e pour des enqu√™tes professionnelles.")
    
    with col2:
        st.subheader("üìù Formulaire Google Forms")
        st.markdown("""
        Vous pr√©f√©rez **Google Forms** ? Remplissez ce formulaire pour partager vos commentaires et suggestions.
        
        Interface simple et famili√®re.
        """)
        
        st.link_button(
            "üîó Ouvrir le formulaire Google Forms",
            "https://docs.google.com/forms/d/e/1FAIpQLSfZWFZCFv5vK3ULo0TK5kJAhojavgBRrAk8LJhT64afKlnhYw/viewform?usp=dialog",
            use_container_width=True
        )
        
        st.markdown("---")
        st.info("üí° **Google Forms** permet un acc√®s rapide et facile depuis n'importe quel appareil.")
    
    st.markdown("---")
    
    # Section pourquoi √©valuer
    st.subheader("‚ùì Pourquoi votre √©valuation est importante")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        ### üéØ Am√©lioration continue
        Vos retours nous aident √† identifier les fonctionnalit√©s √† am√©liorer.
        """)
    
    with col2:
        st.markdown("""
        ### üí° Nouvelles fonctionnalit√©s
        Vos suggestions guident le d√©veloppement de nouvelles features.
        """)
    
    with col3:
        st.markdown("""
        ### ü§ù Exp√©rience utilisateur
        Votre avis fa√ßonne l'√©volution de l'application.
        """)
    
    st.success("‚úÖ Merci d'avance pour votre contribution !")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; padding: 20px; background: rgba(255, 255, 255, 0.03); border-radius: 10px; margin-top: 50px;'>
    <p style='color: #cbd5e0; margin: 0;'>D√©velopp√© avec ‚ù§Ô∏è par Streamlit | Donn√©es de <a href='https://sn.coinafrique.com' target='_blank' style='color: #4FD1C5;'>CoinAfrique S√©n√©gal</a></p>
    <p style='font-size: 12px; color: #718096; margin-top: 10px;'>¬© 2024 - Tous droits r√©serv√©s</p>
</div>
""", unsafe_allow_html=True)
